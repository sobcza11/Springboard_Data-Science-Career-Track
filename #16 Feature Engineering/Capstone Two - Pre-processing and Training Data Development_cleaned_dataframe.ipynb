{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Two - Pre-processing and Training Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The enclosed represents Chapter 16.3 of the Springboard Data Scientist Career Track. The structure is as follows:\n",
    "   * Creating Dummy Variables\n",
    "   * Splitting the Data into Training & Testing subsets for Machine Learning\n",
    "   * Standardized Scaling\n",
    "\n",
    "I hope this submission shows that I understand when to apply the proper steps.\n",
    "\n",
    "This code is built in Jupyter Notebook & uploaded on Github.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the relevant libraries to start**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary tools required in the correct lines below\n",
    "import quandl\n",
    "from fredapi import Fred\n",
    "from getpass import getpass\n",
    "import investpy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "import os\n",
    "import lxml\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import collections\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up the date time stamps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be needed later\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "year = now.strftime(\"%Y\")\n",
    "month = now.strftime(\"%m\")\n",
    "day = now.strftime(\"%d\")\n",
    "today_y_m_d_dash = now.strftime(\"%Y-%m-%d\")\n",
    "today_d_m_y_dash = now.strftime(\"%d/%m/%Y\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Establishing connections to the relevant Application Programming Interface's ( if applicable ).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "# Importing Quandl API requires a password\n",
    "# If you don't have one, please see the link below\n",
    "# https://docs.quandl.com/docs#section-authentication\n",
    "\n",
    "my_quandl_API = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl.ApiConfig.api_key = my_quandl_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "# Importing FRED API requires a password ( FRED stands for Federal Reserve Economic Data )\n",
    "# If you don't have one, please see the link below\n",
    "# https://fred.stlouisfed.org/docs/api/fred/\n",
    "\n",
    "my_FRED_API = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "fred = Fred(api_key=my_FRED_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Establishing a color scale for heatmaps which will be used later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict = {'green':  ((0.0, 0.0, 0.0),   # no red at 0\n",
    "                  (0.5, 1.0, 1.0),   # all channels set to 1.0 at 0.5 to create white\n",
    "                  (1.0, 0.8, 0.8)),  # set to 0.8 so its not too bright at 1\n",
    "\n",
    "        'red': ((0.0, 0.8, 0.8),   # set to 0.8 so its not too bright at 0\n",
    "                  (0.5, 1.0, 1.0),   # all channels set to 1.0 at 0.5 to create white\n",
    "                  (1.0, 0.0, 0.0)),  # no green at 1\n",
    "\n",
    "        'blue':  ((0.0, 0.0, 0.0),   # no blue at 0\n",
    "                  (0.5, 1.0, 1.0),   # all channels set to 1.0 at 0.5 to create white\n",
    "                  (1.0, 0.0, 0.0))   # no blue at 1\n",
    "       }\n",
    "\n",
    "# Create the colormap using the dictionary\n",
    "GnRd = colors.LinearSegmentedColormap('GnRd', cdict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the dataframe from the previous Exploratory Data Analysis ( EDA ) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./_Capstone_One_Inflation/data/1.0_MAIN/QonQ_main_roll.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, the dataframe is composed of a quarterly change ( back ) on both Inflation & the Variables. The variables, however, are taking a rolling average. The rational is based on the idea that one of the variables may have had a bad day / week at the end of their respective term. If so, they may not properly display the impact they may have had on inflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Wages CPI</th>\n",
       "      <th>WTI</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Soybeans</th>\n",
       "      <th>Natural Gas</th>\n",
       "      <th>Heating Oil</th>\n",
       "      <th>Corn</th>\n",
       "      <th>Wheat</th>\n",
       "      <th>...</th>\n",
       "      <th>Lean Hogs</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Lumber</th>\n",
       "      <th>Capacity Utilization</th>\n",
       "      <th>GDP</th>\n",
       "      <th>M2 Velocity</th>\n",
       "      <th>PMI</th>\n",
       "      <th>USD Index</th>\n",
       "      <th>Initial Jobless Claims</th>\n",
       "      <th>Unemployment Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-28 00:00:00</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.294725</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.235484</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>0.362725</td>\n",
       "      <td>0.267969</td>\n",
       "      <td>0.081492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071797</td>\n",
       "      <td>0.153711</td>\n",
       "      <td>0.364326</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>-0.028476</td>\n",
       "      <td>32916.66667</td>\n",
       "      <td>-0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-31 00:00:00</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.133619</td>\n",
       "      <td>0.149469</td>\n",
       "      <td>0.247356</td>\n",
       "      <td>0.133913</td>\n",
       "      <td>0.212935</td>\n",
       "      <td>0.244380</td>\n",
       "      <td>0.075828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083947</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>0.119677</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>-0.021939</td>\n",
       "      <td>-17083.33333</td>\n",
       "      <td>-1.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-31 00:00:00</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.045217</td>\n",
       "      <td>0.110950</td>\n",
       "      <td>0.212504</td>\n",
       "      <td>0.331085</td>\n",
       "      <td>0.075287</td>\n",
       "      <td>0.227807</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251831</td>\n",
       "      <td>0.183723</td>\n",
       "      <td>0.017824</td>\n",
       "      <td>0.022883</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.020209</td>\n",
       "      <td>-234000.00000</td>\n",
       "      <td>-2.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-30 00:00:00</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.111624</td>\n",
       "      <td>0.189713</td>\n",
       "      <td>0.400814</td>\n",
       "      <td>-0.024694</td>\n",
       "      <td>0.194635</td>\n",
       "      <td>0.137836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340989</td>\n",
       "      <td>0.145086</td>\n",
       "      <td>0.352576</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>-0.022875</td>\n",
       "      <td>-412333.33330</td>\n",
       "      <td>-2.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-31 00:00:00</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.268018</td>\n",
       "      <td>0.150999</td>\n",
       "      <td>0.135852</td>\n",
       "      <td>0.421347</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.128424</td>\n",
       "      <td>0.112240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221210</td>\n",
       "      <td>0.164845</td>\n",
       "      <td>0.733392</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>-0.042067</td>\n",
       "      <td>-604333.33330</td>\n",
       "      <td>-3.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date  Inflation  Wages CPI       WTI    Copper  Soybeans  \\\n",
       "0  2021-02-28 00:00:00      0.501   0.007630  0.294725  0.182753  0.235484   \n",
       "1  2021-01-31 00:00:00      0.218   0.006251  0.133619  0.149469  0.247356   \n",
       "2  2020-12-31 00:00:00     -0.009   0.006591  0.045217  0.110950  0.212504   \n",
       "3  2020-11-30 00:00:00     -0.135   0.009198  0.012381  0.111624  0.189713   \n",
       "4  2020-10-31 00:00:00      0.196   0.012842  0.268018  0.150999  0.135852   \n",
       "\n",
       "   Natural Gas  Heating Oil      Corn     Wheat  ...  Lean Hogs     Sugar  \\\n",
       "0     0.039364     0.362725  0.267969  0.081492  ...   0.071797  0.153711   \n",
       "1     0.133913     0.212935  0.244380  0.075828  ...   0.083947  0.167539   \n",
       "2     0.331085     0.075287  0.227807  0.121747  ...   0.251831  0.183723   \n",
       "3     0.400814    -0.024694  0.194635  0.137836  ...   0.340989  0.145086   \n",
       "4     0.421347     0.081213  0.128424  0.112240  ...   0.221210  0.164845   \n",
       "\n",
       "     Lumber  Capacity Utilization       GDP  M2 Velocity       PMI  USD Index  \\\n",
       "0  0.364326              0.019749  0.015004    -0.012195  2.600000  -0.028476   \n",
       "1  0.119677              0.026555  0.015004    -0.012195  2.266667  -0.021939   \n",
       "2  0.017824              0.022883  0.015004    -0.012195  4.000000  -0.020209   \n",
       "3  0.352576              0.030228  0.015004    -0.012195  3.566667  -0.022875   \n",
       "4  0.733392              0.063448  0.015004    -0.012195  7.033333  -0.042067   \n",
       "\n",
       "   Initial Jobless Claims  Unemployment Rate  \n",
       "0             32916.66667          -0.733333  \n",
       "1            -17083.33333          -1.133333  \n",
       "2           -234000.00000          -2.033333  \n",
       "3           -412333.33330          -2.766667  \n",
       "4           -604333.33330          -3.833333  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per below, they have been scraped ( i.e. no null values ) & they all came in from the the API as floats ( which we want ). The `Date` is the only non-float variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Date                    312 non-null    object \n",
      " 1   Inflation               312 non-null    float64\n",
      " 2   Wages CPI               312 non-null    float64\n",
      " 3   WTI                     312 non-null    float64\n",
      " 4   Copper                  312 non-null    float64\n",
      " 5   Soybeans                312 non-null    float64\n",
      " 6   Natural Gas             312 non-null    float64\n",
      " 7   Heating Oil             312 non-null    float64\n",
      " 8   Corn                    312 non-null    float64\n",
      " 9   Wheat                   312 non-null    float64\n",
      " 10  Cattle                  312 non-null    float64\n",
      " 11  Lean Hogs               312 non-null    float64\n",
      " 12  Sugar                   312 non-null    float64\n",
      " 13  Lumber                  312 non-null    float64\n",
      " 14  Capacity Utilization    312 non-null    float64\n",
      " 15  GDP                     312 non-null    float64\n",
      " 16  M2 Velocity             312 non-null    float64\n",
      " 17  PMI                     312 non-null    float64\n",
      " 18  USD Index               312 non-null    float64\n",
      " 19  Initial Jobless Claims  312 non-null    float64\n",
      " 20  Unemployment Rate       312 non-null    float64\n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 51.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 21)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Wages CPI</th>\n",
       "      <th>WTI</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Soybeans</th>\n",
       "      <th>Natural Gas</th>\n",
       "      <th>Heating Oil</th>\n",
       "      <th>Corn</th>\n",
       "      <th>Wheat</th>\n",
       "      <th>Cattle</th>\n",
       "      <th>Lean Hogs</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Lumber</th>\n",
       "      <th>Capacity Utilization</th>\n",
       "      <th>GDP</th>\n",
       "      <th>M2 Velocity</th>\n",
       "      <th>PMI</th>\n",
       "      <th>USD Index</th>\n",
       "      <th>Initial Jobless Claims</th>\n",
       "      <th>Unemployment Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>3.120000e+02</td>\n",
       "      <td>312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.030804</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>0.019810</td>\n",
       "      <td>0.012885</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.014929</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>0.028027</td>\n",
       "      <td>-0.000384</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>-0.004439</td>\n",
       "      <td>0.073184</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>3.685096e+03</td>\n",
       "      <td>0.006090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.827474</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.150741</td>\n",
       "      <td>0.120212</td>\n",
       "      <td>0.098168</td>\n",
       "      <td>0.197019</td>\n",
       "      <td>0.137546</td>\n",
       "      <td>0.122589</td>\n",
       "      <td>0.109806</td>\n",
       "      <td>0.066072</td>\n",
       "      <td>0.140843</td>\n",
       "      <td>0.147224</td>\n",
       "      <td>0.157614</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.022552</td>\n",
       "      <td>2.960773</td>\n",
       "      <td>0.034428</td>\n",
       "      <td>3.034924e+05</td>\n",
       "      <td>0.880617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.846000</td>\n",
       "      <td>-0.034864</td>\n",
       "      <td>-0.528002</td>\n",
       "      <td>-0.490200</td>\n",
       "      <td>-0.327256</td>\n",
       "      <td>-0.378821</td>\n",
       "      <td>-0.456848</td>\n",
       "      <td>-0.340215</td>\n",
       "      <td>-0.299369</td>\n",
       "      <td>-0.209991</td>\n",
       "      <td>-0.322853</td>\n",
       "      <td>-0.362170</td>\n",
       "      <td>-0.318534</td>\n",
       "      <td>-0.128528</td>\n",
       "      <td>-0.094662</td>\n",
       "      <td>-0.200725</td>\n",
       "      <td>-11.833333</td>\n",
       "      <td>-0.072180</td>\n",
       "      <td>-2.430333e+06</td>\n",
       "      <td>-4.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.387750</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>-0.057181</td>\n",
       "      <td>-0.050026</td>\n",
       "      <td>-0.041698</td>\n",
       "      <td>-0.088850</td>\n",
       "      <td>-0.050995</td>\n",
       "      <td>-0.056145</td>\n",
       "      <td>-0.055938</td>\n",
       "      <td>-0.039485</td>\n",
       "      <td>-0.075435</td>\n",
       "      <td>-0.080698</td>\n",
       "      <td>-0.073570</td>\n",
       "      <td>-0.004309</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>-0.007373</td>\n",
       "      <td>-1.700000</td>\n",
       "      <td>-0.024314</td>\n",
       "      <td>-9.958333e+03</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.025500</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.025297</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.011647</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>-0.010051</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.011626</td>\n",
       "      <td>-0.002556</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>-2.625000e+03</td>\n",
       "      <td>-0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.333250</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.086206</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.157548</td>\n",
       "      <td>0.104415</td>\n",
       "      <td>0.076297</td>\n",
       "      <td>0.078351</td>\n",
       "      <td>0.055361</td>\n",
       "      <td>0.113479</td>\n",
       "      <td>0.100615</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>0.014817</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>1.675000</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>5.166667e+03</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.007000</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.586463</td>\n",
       "      <td>0.496467</td>\n",
       "      <td>0.288663</td>\n",
       "      <td>0.629854</td>\n",
       "      <td>0.362725</td>\n",
       "      <td>0.475869</td>\n",
       "      <td>0.443412</td>\n",
       "      <td>0.165321</td>\n",
       "      <td>0.376706</td>\n",
       "      <td>0.604139</td>\n",
       "      <td>0.931183</td>\n",
       "      <td>0.096035</td>\n",
       "      <td>0.084535</td>\n",
       "      <td>0.040798</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>0.118429</td>\n",
       "      <td>3.365750e+06</td>\n",
       "      <td>9.266667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Inflation   Wages CPI         WTI      Copper    Soybeans  \\\n",
       "count  312.000000  312.000000  312.000000  312.000000  312.000000   \n",
       "mean    -0.030804    0.005489    0.020214    0.019810    0.012885   \n",
       "std      0.827474    0.005800    0.150741    0.120212    0.098168   \n",
       "min     -4.846000   -0.034864   -0.528002   -0.490200   -0.327256   \n",
       "25%     -0.387750    0.003967   -0.057181   -0.050026   -0.041698   \n",
       "50%     -0.025500    0.006300    0.025297    0.009065    0.006706   \n",
       "75%      0.333250    0.008169    0.115388    0.086206    0.061490   \n",
       "max      4.007000    0.023370    0.586463    0.496467    0.288663   \n",
       "\n",
       "       Natural Gas  Heating Oil        Corn       Wheat      Cattle  \\\n",
       "count   312.000000   312.000000  312.000000  312.000000  312.000000   \n",
       "mean      0.035417     0.019414    0.014929    0.016604    0.006404   \n",
       "std       0.197019     0.137546    0.122589    0.109806    0.066072   \n",
       "min      -0.378821    -0.456848   -0.340215   -0.299369   -0.209991   \n",
       "25%      -0.088850    -0.050995   -0.056145   -0.055938   -0.039485   \n",
       "50%       0.007933     0.020651    0.005665    0.006844    0.011647   \n",
       "75%       0.157548     0.104415    0.076297    0.078351    0.055361   \n",
       "max       0.629854     0.362725    0.475869    0.443412    0.165321   \n",
       "\n",
       "        Lean Hogs       Sugar      Lumber  Capacity Utilization         GDP  \\\n",
       "count  312.000000  312.000000  312.000000            312.000000  312.000000   \n",
       "mean     0.018066    0.019915    0.028027             -0.000384    0.010657   \n",
       "std      0.140843    0.147224    0.157614              0.017885    0.014045   \n",
       "min     -0.322853   -0.362170   -0.318534             -0.128528   -0.094662   \n",
       "25%     -0.075435   -0.080698   -0.073570             -0.004309    0.008557   \n",
       "50%      0.007895   -0.010051    0.016908              0.001742    0.011626   \n",
       "75%      0.113479    0.100615    0.112200              0.006261    0.014817   \n",
       "max      0.376706    0.604139    0.931183              0.096035    0.084535   \n",
       "\n",
       "       M2 Velocity         PMI   USD Index  Initial Jobless Claims  \\\n",
       "count   312.000000  312.000000  312.000000            3.120000e+02   \n",
       "mean     -0.004439    0.073184    0.000752            3.685096e+03   \n",
       "std       0.022552    2.960773    0.034428            3.034924e+05   \n",
       "min      -0.200725  -11.833333   -0.072180           -2.430333e+06   \n",
       "25%      -0.007373   -1.700000   -0.024314           -9.958333e+03   \n",
       "50%      -0.002556   -0.100000    0.000669           -2.625000e+03   \n",
       "75%       0.003964    1.675000    0.021954            5.166667e+03   \n",
       "max       0.040798   10.666667    0.118429            3.365750e+06   \n",
       "\n",
       "       Unemployment Rate  \n",
       "count         312.000000  \n",
       "mean            0.006090  \n",
       "std             0.880617  \n",
       "min            -4.266667  \n",
       "25%            -0.200000  \n",
       "50%            -0.066667  \n",
       "75%             0.066667  \n",
       "max             9.266667  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies( df, columns=['Inflation'], prefix='D' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Wages CPI</th>\n",
       "      <th>WTI</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Soybeans</th>\n",
       "      <th>Natural Gas</th>\n",
       "      <th>Heating Oil</th>\n",
       "      <th>Corn</th>\n",
       "      <th>Wheat</th>\n",
       "      <th>Cattle</th>\n",
       "      <th>...</th>\n",
       "      <th>D_1.4609999999999999</th>\n",
       "      <th>D_1.5290000000000001</th>\n",
       "      <th>D_1.5319999999999998</th>\n",
       "      <th>D_1.663</th>\n",
       "      <th>D_1.9140000000000001</th>\n",
       "      <th>D_2.157</th>\n",
       "      <th>D_2.336</th>\n",
       "      <th>D_2.8089999999999997</th>\n",
       "      <th>D_3.322</th>\n",
       "      <th>D_4.007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-28 00:00:00</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.294725</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.235484</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>0.362725</td>\n",
       "      <td>0.267969</td>\n",
       "      <td>0.081492</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-31 00:00:00</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.133619</td>\n",
       "      <td>0.149469</td>\n",
       "      <td>0.247356</td>\n",
       "      <td>0.133913</td>\n",
       "      <td>0.212935</td>\n",
       "      <td>0.244380</td>\n",
       "      <td>0.075828</td>\n",
       "      <td>0.052881</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date  Wages CPI       WTI    Copper  Soybeans  Natural Gas  \\\n",
       "0  2021-02-28 00:00:00   0.007630  0.294725  0.182753  0.235484     0.039364   \n",
       "1  2021-01-31 00:00:00   0.006251  0.133619  0.149469  0.247356     0.133913   \n",
       "\n",
       "   Heating Oil      Corn     Wheat    Cattle  ...  D_1.4609999999999999  \\\n",
       "0     0.362725  0.267969  0.081492  0.056126  ...                     0   \n",
       "1     0.212935  0.244380  0.075828  0.052881  ...                     0   \n",
       "\n",
       "   D_1.5290000000000001  D_1.5319999999999998  D_1.663  D_1.9140000000000001  \\\n",
       "0                     0                     0        0                     0   \n",
       "1                     0                     0        0                     0   \n",
       "\n",
       "   D_2.157  D_2.336  D_2.8089999999999997  D_3.322  D_4.007  \n",
       "0        0        0                     0        0        0  \n",
       "1        0        0                     0        0        0  \n",
       "\n",
       "[2 rows x 307 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Wages CPI</th>\n",
       "      <th>WTI</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Soybeans</th>\n",
       "      <th>Natural Gas</th>\n",
       "      <th>Heating Oil</th>\n",
       "      <th>Corn</th>\n",
       "      <th>Wheat</th>\n",
       "      <th>...</th>\n",
       "      <th>Lean Hogs</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Lumber</th>\n",
       "      <th>Capacity Utilization</th>\n",
       "      <th>GDP</th>\n",
       "      <th>M2 Velocity</th>\n",
       "      <th>PMI</th>\n",
       "      <th>USD Index</th>\n",
       "      <th>Initial Jobless Claims</th>\n",
       "      <th>Unemployment Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-28 00:00:00</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.294725</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.235484</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>0.362725</td>\n",
       "      <td>0.267969</td>\n",
       "      <td>0.081492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071797</td>\n",
       "      <td>0.153711</td>\n",
       "      <td>0.364326</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>-0.028476</td>\n",
       "      <td>32916.66667</td>\n",
       "      <td>-0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-31 00:00:00</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.133619</td>\n",
       "      <td>0.149469</td>\n",
       "      <td>0.247356</td>\n",
       "      <td>0.133913</td>\n",
       "      <td>0.212935</td>\n",
       "      <td>0.244380</td>\n",
       "      <td>0.075828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083947</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>0.119677</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>-0.021939</td>\n",
       "      <td>-17083.33333</td>\n",
       "      <td>-1.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-31 00:00:00</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.045217</td>\n",
       "      <td>0.110950</td>\n",
       "      <td>0.212504</td>\n",
       "      <td>0.331085</td>\n",
       "      <td>0.075287</td>\n",
       "      <td>0.227807</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251831</td>\n",
       "      <td>0.183723</td>\n",
       "      <td>0.017824</td>\n",
       "      <td>0.022883</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.020209</td>\n",
       "      <td>-234000.00000</td>\n",
       "      <td>-2.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-30 00:00:00</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.111624</td>\n",
       "      <td>0.189713</td>\n",
       "      <td>0.400814</td>\n",
       "      <td>-0.024694</td>\n",
       "      <td>0.194635</td>\n",
       "      <td>0.137836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340989</td>\n",
       "      <td>0.145086</td>\n",
       "      <td>0.352576</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>-0.022875</td>\n",
       "      <td>-412333.33330</td>\n",
       "      <td>-2.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-31 00:00:00</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.268018</td>\n",
       "      <td>0.150999</td>\n",
       "      <td>0.135852</td>\n",
       "      <td>0.421347</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.128424</td>\n",
       "      <td>0.112240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221210</td>\n",
       "      <td>0.164845</td>\n",
       "      <td>0.733392</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>-0.042067</td>\n",
       "      <td>-604333.33330</td>\n",
       "      <td>-3.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date  Inflation  Wages CPI       WTI    Copper  Soybeans  \\\n",
       "0  2021-02-28 00:00:00      0.501   0.007630  0.294725  0.182753  0.235484   \n",
       "1  2021-01-31 00:00:00      0.218   0.006251  0.133619  0.149469  0.247356   \n",
       "2  2020-12-31 00:00:00     -0.009   0.006591  0.045217  0.110950  0.212504   \n",
       "3  2020-11-30 00:00:00     -0.135   0.009198  0.012381  0.111624  0.189713   \n",
       "4  2020-10-31 00:00:00      0.196   0.012842  0.268018  0.150999  0.135852   \n",
       "\n",
       "   Natural Gas  Heating Oil      Corn     Wheat  ...  Lean Hogs     Sugar  \\\n",
       "0     0.039364     0.362725  0.267969  0.081492  ...   0.071797  0.153711   \n",
       "1     0.133913     0.212935  0.244380  0.075828  ...   0.083947  0.167539   \n",
       "2     0.331085     0.075287  0.227807  0.121747  ...   0.251831  0.183723   \n",
       "3     0.400814    -0.024694  0.194635  0.137836  ...   0.340989  0.145086   \n",
       "4     0.421347     0.081213  0.128424  0.112240  ...   0.221210  0.164845   \n",
       "\n",
       "     Lumber  Capacity Utilization       GDP  M2 Velocity       PMI  USD Index  \\\n",
       "0  0.364326              0.019749  0.015004    -0.012195  2.600000  -0.028476   \n",
       "1  0.119677              0.026555  0.015004    -0.012195  2.266667  -0.021939   \n",
       "2  0.017824              0.022883  0.015004    -0.012195  4.000000  -0.020209   \n",
       "3  0.352576              0.030228  0.015004    -0.012195  3.566667  -0.022875   \n",
       "4  0.733392              0.063448  0.015004    -0.012195  7.033333  -0.042067   \n",
       "\n",
       "   Initial Jobless Claims  Unemployment Rate  \n",
       "0             32916.66667          -0.733333  \n",
       "1            -17083.33333          -1.133333  \n",
       "2           -234000.00000          -2.033333  \n",
       "3           -412333.33330          -2.766667  \n",
       "4           -604333.33330          -3.833333  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we knew going into the process that the entire data set is composed of \"non categorical\" data, notably floats, we undertook dummy variable creation process to double confirm.\n",
    "\n",
    "**We will proceed forward without the dummy variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Split data into training and testing subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now undertake the train / test split. Please note, there are three (3) scaling approaches ( next section ) & each one will have its own data frame. Listed below is a summary of the scaling names, the approach & the name of the respective data frames which we will formalize in the next section. Each will have a train test split formalized here:\n",
    "\n",
    "   * **MinMaxScaler** ( often called Normalization )\n",
    "      * This approach reassigns the values from 0 -> 1\n",
    "      * Data Frame Name  |  `df_MM_only`\n",
    "   * **Standardization**\n",
    "      * This approach finds the mean of the data, assigns that as Zero & the values presented are standard deviated moves\n",
    "      * Data Frame Name  |  `df_SS_only`\n",
    "   * **Log Transformation**\n",
    "      * This approach usually is used with data that has long tails\n",
    "      * Data Frame Name  |  `df_Log_only`\n",
    "\n",
    "The creation of these train / test splits will start here but before we proceed we will need to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from library.sb_utils import save_file\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Train test split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's see what a `70% / 30% Train/Test Split` looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train | 218.39999999999998 \n",
      " Test  | 93.6\n"
     ]
    }
   ],
   "source": [
    "print(' Train |', len(df) * 0.7, '\\n','Test  |', len(df) * 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='Inflation'),\n",
    "                                                    df.Inflation, test_size=0.3,\n",
    "                                                    random_state=47\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((218, 20), (94, 20))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the lingering 0.2 on the Train Set went to the Test Set; 'rounding'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((218,), (94,))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((218, 19), (94, 19))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list = ['Date']\n",
    "date_train = X_train[['Date']]\n",
    "date_test = X_train[['Date']]\n",
    "\n",
    "X_train.drop(columns=date_list, inplace=True)\n",
    "X_test.drop(columns=date_list, inplace=True)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wages CPI                 float64\n",
       "WTI                       float64\n",
       "Copper                    float64\n",
       "Soybeans                  float64\n",
       "Natural Gas               float64\n",
       "Heating Oil               float64\n",
       "Corn                      float64\n",
       "Wheat                     float64\n",
       "Cattle                    float64\n",
       "Lean Hogs                 float64\n",
       "Sugar                     float64\n",
       "Lumber                    float64\n",
       "Capacity Utilization      float64\n",
       "GDP                       float64\n",
       "M2 Velocity               float64\n",
       "PMI                       float64\n",
       "USD Index                 float64\n",
       "Initial Jobless Claims    float64\n",
       "Unemployment Rate         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wages CPI                 float64\n",
       "WTI                       float64\n",
       "Copper                    float64\n",
       "Soybeans                  float64\n",
       "Natural Gas               float64\n",
       "Heating Oil               float64\n",
       "Corn                      float64\n",
       "Wheat                     float64\n",
       "Cattle                    float64\n",
       "Lean Hogs                 float64\n",
       "Sugar                     float64\n",
       "Lumber                    float64\n",
       "Capacity Utilization      float64\n",
       "GDP                       float64\n",
       "M2 Velocity               float64\n",
       "PMI                       float64\n",
       "USD Index                 float64\n",
       "Initial Jobless Claims    float64\n",
       "Unemployment Rate         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have only numeric features in your X now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Initial Not-Even Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now start to see how good the mean is as a predictor. In other words, what if you simply say your best guess for inflation is ___?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0348"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean = y_train.mean()\n",
    "round(train_mean,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0308"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inf_mean = round(df['Inflation'].mean(),4)\n",
    "df_inf_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.004025688073394491"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = ( df_inf_mean * -1 ) - ( train_mean * -1 )\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this? How closely does this match, or explain, the actual values? There are many ways of assessing how good one set of values agrees with another, which brings us to the subject of metrics.\n",
    "\n",
    "That said, it's close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03482569]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "dumb_reg.constant_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.1 R-squared or coefficient of determination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y,ypred):\n",
    "    ybar = np.sum(y) / len(y)\n",
    "    sum_sq_tot = np.sum((y - ybar)**2)\n",
    "    sum_sq_res = np.sum((y - ypred)**2)\n",
    "    R2 = 1.0 - sum_sq_res - sum_sq_tot\n",
    "    return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03482569, -0.03482569, -0.03482569, -0.03482569, -0.03482569])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred_ = train_mean * np.ones(len(y_train))\n",
    "y_tr_pred_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03482569, -0.03482569, -0.03482569, -0.03482569, -0.03482569])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred = dumb_reg.predict(X_train)\n",
    "y_tr_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DummyRegressor` produces exactly the same results and saves us having to mess about broadcasting the mean to an array of the appropriate length. It also gives us an object with `fit()` and `predict()` methods as well so we can use them as conveniently as any other `sklearn` estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-308.6062827522935"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-115.27892421268626"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_pred = train_mean * np.ones(len(y_test))\n",
    "r_squared(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2 Mean Absolute Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply speaking we are taking the average of the absolute errors:\n",
    "$$MAE = \\frac{1}{n}\\sum_i^n|y_i - \\hat{y}|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y, ypred):\n",
    "    abs_error = np.abs( y - ypred )\n",
    "    mae = np.mean(abs_error)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5430366972477064"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5542122779621316"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.3 Mean Squared Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common metric (and an important one internally for optimizing machine learning models) is the mean squared error. This is simply the average of the square of the errors:\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum_i^n(y_i - \\hat{y})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y,ypred):\n",
    "    sq_error = ( y - ypred )**2\n",
    "    mse = np.mean(sq_error)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7101061531015902"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6185939867578665"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84267797, 0.78650746])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt([mse(y_train, y_tr_pred), mse(y_test, y_te_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 sklearn metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to compute, `sklearn.metrics` provides many commonly used metrics, including the ones above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.1 R-squared**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -0.0002880609661533029)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Mean Absolute Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5430366972477064, 0.5542122779621317)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Mean squared error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7101061531015906, 0.6185939867578666)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MinMaxScaler** | *Assignment to its respective data frames.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_MM = pd.DataFrame(X_train)\n",
    "X_test_MM = pd.DataFrame(X_test)\n",
    "y_train_MM = pd.DataFrame(y_train)\n",
    "y_test_MM = pd.DataFrame(y_test)\n",
    "y_tr_pred_MM = pd.DataFrame(y_tr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardization** | *Assignment to its respective data frames.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SS = pd.DataFrame(X_train)\n",
    "X_test_SS = pd.DataFrame(X_test)\n",
    "y_train_SS = pd.DataFrame(y_train)\n",
    "y_test_SS = pd.DataFrame(y_test)\n",
    "y_tr_pred_SS = pd.DataFrame(y_tr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log Transformation** | *Assignment to its respective data frames.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Log = pd.DataFrame(X_train)\n",
    "X_test_Log = pd.DataFrame(X_test)\n",
    "y_train_Log = pd.DataFrame(y_train)\n",
    "y_test_Log = pd.DataFrame(y_test)\n",
    "y_tr_pred_Log = pd.DataFrame(y_tr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Scale standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the train / test splits have been completed, we will implement three (3) scaling approaches listed below. Each one has a different approach with a basic summary below each & their data frame names from the end of the previous section:\n",
    "\n",
    "   * **MinMaxScaler** ( often called Normalization )\n",
    "      * This approach reassigns the values from 0 -> 1\n",
    "   * **Standardization**\n",
    "      * This approach finds the mean of the data, assigns that as Zero & the values presented are standard deviated moves\n",
    "   * **Log Transformation**\n",
    "      * This approach usually is used with data that has long tails\n",
    "\n",
    "Before we proceed we will need to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_MM = make_pipeline(\n",
    "    SimpleImputer(strategy='median'), \n",
    "    MinMaxScaler(), \n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipe_MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(pipe_MM, 'fit'), hasattr(pipe_MM, 'predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_MM = pd.DataFrame(X_train)\n",
    "# X_test_MM = pd.DataFrame(X_test)\n",
    "# y_train_MM = pd.DataFrame(y_train)\n",
    "# y_test_MM = pd.DataFrame(y_test)\n",
    "# y_tr_pred_MM = pd.DataFrame(y_tr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
       "                ('minmaxscaler', MinMaxScaler()),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_MM.fit(X_train_MM, y_train_MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred_MM = pipe_MM.predict(X_train_MM)\n",
    "y_te_pred_MM = pipe_MM.predict(X_test_MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4241012214816976, 0.327593460165006)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred_MM), r2_score(y_test, y_te_pred_MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Both the `Training` & `Testing` sets come up below a simple coin flip.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_SS = pd.DataFrame(X_train)\n",
    "# X_test_SS = pd.DataFrame(X_test)\n",
    "# y_train_SS = pd.DataFrame(y_train)\n",
    "# y_test_SS = pd.DataFrame(y_test)\n",
    "# y_tr_pred_SS = pd.DataFrame(y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_SS = make_pipeline(\n",
    "    SimpleImputer(strategy='median'), \n",
    "    StandardScaler(),\n",
    "    SelectKBest(f_regression),\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rands\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('selectkbest',\n",
       "                 SelectKBest(score_func=<function f_regression at 0x000002039C2D3550>)),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_SS.fit(X_train_SS, y_train_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_scaled_SS = scaler.transform(X_train_SS)\n",
    "X_te_scaled_SS = scaler.transform(X_test_SS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using it's `transform()` method to apply the scaling to both the train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_SS)\n",
    "X_tr_scaled_SS = scaler.transform(X_train_SS)\n",
    "X_te_scaled_SS = scaler.transform(X_test_SS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model on the train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X_tr_scaled_SS, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions using the model on both train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred_SS = lm.predict(X_tr_scaled_SS)\n",
    "y_te_pred_SS = lm.predict(X_te_scaled_SS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41581843221746717, 0.327593460165006)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_r2_SS = r2_score(y_train, y_tr_pred_SS), r2_score(y_test, y_te_pred_SS)\n",
    "median_r2_SS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same results as above; both the `Training` & `Testing` sets come up below a simple coin flip.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.2 Defining a new pipeline to select a different number of features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe15_SS = make_pipeline(\n",
    "    SimpleImputer(strategy='median'), \n",
    "    StandardScaler(),\n",
    "    SelectKBest(f_regression, k=15),\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('selectkbest',\n",
       "                 SelectKBest(k=15,\n",
       "                             score_func=<function f_regression at 0x000002039C2D3550>)),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe15_SS.fit(X_train_SS, y_train_SS.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.3 Assess performance on train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but this SimpleImputer is expecting 19 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-274-ba56693e7df7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_tr_pred_SS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe15_SS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_SS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_te_pred_SS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe15_SS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_SS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[0mX_indicator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_indicator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m             X = self._validate_data(X, reset=in_fit,\n\u001b[0m\u001b[0;32m    242\u001b[0m                                     \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                                     \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    375\u001b[0m                 )\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    378\u001b[0m                     \u001b[1;34m'X has {} features, but this {} is expecting {} features '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                     'as input.'.format(n_features, self.__class__.__name__,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features, but this SimpleImputer is expecting 19 features as input."
     ]
    }
   ],
   "source": [
    "y_tr_pred_SS = pipe15_SS.predict(X_train_SS)\n",
    "y_te_pred_SS = pipe15_SS.predict(y_train_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.2 Assessing performance using cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_results_SS = cross_validate(pipe_SS, X_train_SS, y_train_SS, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores_SS = cv_results_SS['test score']\n",
    "# cv_scores_SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.3 Hyperparameter search using GridSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling the above together, we have:\n",
    "* a pipeline that\n",
    "    * imputes missing values\n",
    "    * scales the data\n",
    "    * selects the k best features\n",
    "    * trains a linear regression model\n",
    "* a technique (cross-validation) for estimating model performance\n",
    "\n",
    "Now you want to use cross-validation for multiple values of k and use cross-validation to pick the value of k that gives the best performance. `make_pipeline` automatically names each step as the lowercase name of the step and the parameters of the step are then accessed by appending a double underscore followed by the parameter name. You know the name of the step will be 'selectkbest' and you know the parameter is 'k'.\n",
    "\n",
    "You can also list the names of all the parameters in a pipeline like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'simpleimputer', 'standardscaler', 'selectkbest', 'linearregression', 'simpleimputer__add_indicator', 'simpleimputer__copy', 'simpleimputer__fill_value', 'simpleimputer__missing_values', 'simpleimputer__strategy', 'simpleimputer__verbose', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'selectkbest__k', 'selectkbest__score_func', 'linearregression__copy_X', 'linearregression__fit_intercept', 'linearregression__n_jobs', 'linearregression__normalize'])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_SS.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [k+1 for k in range(len(X_train_SS.columns))]\n",
    "grid_params_SS = {'selectkbest__k': k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid_cv_SS = GridSearchCV(pipe_SS, param_grid=grid_params_SS, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('simpleimputer',\n",
       "                                        SimpleImputer(strategy='median')),\n",
       "                                       ('standardscaler', StandardScaler()),\n",
       "                                       ('selectkbest',\n",
       "                                        SelectKBest(score_func=<function f_regression at 0x000002039C2D3550>)),\n",
       "                                       ('linearregression',\n",
       "                                        LinearRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'selectkbest__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                            12, 13, 14, 15, 16, 17, 18, 19]})"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid_cv_SS.fit(X_train_SS, y_train_SS.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_SS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-278-9fab5ba02b15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_grid_cv_SS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_SS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscore_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_grid_cv_SS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_SS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcv_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlr_grid_cv_SS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_SS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'param_selectkbest__k'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_SS'"
     ]
    }
   ],
   "source": [
    "score_mean = lr_grid_cv_SS.cv_results_SS['mean_test_score']\n",
    "score_std = lr_grid_cv_SS.cv_results_SS['std_test_score']\n",
    "cv_k = [k for k in lr_grid_cv_SS.cv_results_SS['param_selectkbest__k']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions & Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question |** Does my data set have any categorical data, such as Gender or day of the week? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer |** No, it did not have categorical data from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question |** Do my features have data values that range from 0 - 100 or 0-1 or both and more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer |** xxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
